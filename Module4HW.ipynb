{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1557d29",
   "metadata": {},
   "source": [
    "# 1) Creating Monthly Mean SST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0f50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742d40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set time and location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63007a6",
   "metadata": {},
   "source": [
    "# 2) Compute Anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715cef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "def _time_as_float(time: xr.DataArray, time_dim: str) -> xr.DataArray:\n",
    "    # numeric seconds since first timestamp (keeps numbers small)\n",
    "    return (time - time.isel({time_dim: 0})).astype(\"timedelta64[s]\").astype(\"int64\").astype(\"float64\")\n",
    "\n",
    "def linear_detrend(obj: xr.DataArray | xr.Dataset, time_dim: str = \"time\") -> xr.DataArray | xr.Dataset:\n",
    "    \"\"\"\n",
    "    Remove a linear trend y ~ s*(t - t̄_valid) + ȳ_valid at each grid point.\n",
    "    Closed-form LS using reductions; dask-friendly; handles NaNs.\n",
    "    \"\"\"\n",
    "    t = _time_as_float(obj[time_dim], time_dim)  # (time,)\n",
    "    def _detrend_da(da: xr.DataArray) -> xr.DataArray:\n",
    "        da = da.sortby(time_dim).astype(\"float32\")\n",
    "        if hasattr(da.data, \"chunks\"):\n",
    "            da = da.chunk({time_dim: -1})  # one chunk along time\n",
    "        mask = da.notnull()                                # (time, ...)\n",
    "        t_b = t.broadcast_like(da)                         # (time, ...)\n",
    "        t_mean_valid = t_b.where(mask).mean(time_dim, skipna=True)\n",
    "        tc = t_b - t_mean_valid                            # centered time per point\n",
    "        num = (da * tc).sum(time_dim, skipna=True)\n",
    "        den = (tc**2).sum(time_dim, skipna=True)\n",
    "        slope = xr.where(den > 0, num / den, 0.0)\n",
    "        ybar  = da.mean(time_dim, skipna=True)\n",
    "        trend = slope * (t_b - t_mean_valid) + ybar\n",
    "        return (da - trend).astype(\"float32\")\n",
    "    return obj.map(_detrend_da) if isinstance(obj, xr.Dataset) else _detrend_da(obj)\n",
    "\n",
    "def monthly_anom_and_z(\n",
    "    detr: xr.DataArray | xr.Dataset,\n",
    "    time_dim: str = \"time\",\n",
    "    base_period: tuple[str, str] | None = None,\n",
    "    ddof: int = 1,\n",
    "    eps: float = 1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    From linearly-detrended data, remove monthly climatology and compute monthly z-scores.\n",
    "    Returns (anom, z). Works for Dataset or DataArray.\n",
    "    \"\"\"\n",
    "    clim_src = detr if base_period is None else detr.sel({time_dim: slice(*base_period)})\n",
    "    key = f\"{time_dim}.month\"\n",
    "\n",
    "    clim_mean = clim_src.groupby(key).mean(time_dim, skipna=True)\n",
    "    anom = detr.groupby(key) - clim_mean\n",
    "\n",
    "    clim_std = clim_src.groupby(key).std(time_dim, skipna=True, ddof=ddof)\n",
    "    safe_std = xr.where(clim_std > eps, clim_std, np.nan)\n",
    "    z = anom.groupby(key) / safe_std\n",
    "    return anom, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dd5fc",
   "metadata": {},
   "source": [
    "# 3) EOF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ba9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c2793b",
   "metadata": {},
   "source": [
    "# 4) Plot Percent of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7ceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f80bd7",
   "metadata": {},
   "source": [
    "# 5) Reconstruct SST Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2c6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4609a81f",
   "metadata": {},
   "source": [
    "# 6) Map of Pearson's Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3155806",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
